{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Team1_Math490_Project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqNVvabzSPRF",
        "colab_type": "text"
      },
      "source": [
        "# **Principal Component Analysis for Dataset Optimization with Dimension Reduction**\n",
        "Principal Component Analysis is used to find patterns in data and then express them as principal components, which emphasize the similarities and differences that are discovered. These principal components can then be examined to see what portion of information each one contributes to the whole. This will allow for selection and removal of those principal components contributing very little. \n",
        "\n",
        "This is very useful for machine learning purposes on large datasets with many attributes, otherwise known as the dimensions of a dataset. This is because after elimination, the remaining principal components can be used as the new attributes; representative, without significant loss, of the information provided by the original dataset. This compression of data provides a reduction in the overall dimensionality and a new dataset which will be more manageable for use with machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLLi8EfOts7i",
        "colab_type": "text"
      },
      "source": [
        "# **Importing Packages and Loading Wine Datasets**\n",
        "\n",
        "White Wine and Red Wine datasets were imported from UCI's Machine Learning Repository, and also joined together to form an additional dataset of all wine. Column names were changed to remove spaces so coding with attributes is easier later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Ilihn1dDIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports\n",
        "#Most packages used, and the rest were experimented with\n",
        "import numpy as np\n",
        "import sympy as sp\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "from scipy import stats\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHfuJKS1lHqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load White Wine Dataset into Pandas DataFrame from UCI Database\n",
        "urlW = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
        "ww = pd.read_csv(urlW, sep = ';' , header = 'infer')\n",
        "\n",
        "#Load Red Wine Dataset into Pandas DataFrame from UCI Database\n",
        "urlR = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "rw = pd.read_csv(urlR, sep = ';' , header = 'infer')\n",
        "\n",
        "#Remove Spaces from Column Names\n",
        "ww.columns = ['fixedAcidity', 'volatileAcidity', 'citricAcid', 'residualSugar', 'chlorides','freeSulfurDioxide', 'totalSulfurDioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
        "rw.columns = ['fixedAcidity', 'volatileAcidity', 'citricAcid', 'residualSugar', 'chlorides','freeSulfurDioxide', 'totalSulfurDioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
        "\n",
        "# Merged Dataframes of Red and White Wine for a combined list of wine\n",
        "frames = [rw,ww]\n",
        "aw = pd.concat(frames, keys=['Red Wine', 'White Wine'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXhGMSzSTTJ8",
        "colab_type": "text"
      },
      "source": [
        "# **Exploratory Data Analysis**\n",
        "\n",
        "The data used for our project is from two datasets concering the characteristics of wine and the possible effect they have on the overall quality of wine. One dataset is about white wine, the second red wine, and the third dataset is a combined dataset of red and white wine. The large difference in the number of instances between the red and white wine datasets could possibly be significant. The fact the white and red wines will have different values for their attributes may be significant. These two factors were significant enough that the decision was made to explore them seperately, along with them combined in one list.\n",
        "\n",
        "Initial observations drawn from the data shows 4898 instances of white wine and 1599 instances of red wine, for a total of 6497 samples.\n",
        "\n",
        "There are 12 attributes, 11 of which are predictor variables and 1 target variable concering quality. It is important to explore the data further to search for errors, outliers, or other significant observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9IUeRbMyVzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#View Number of Instances and Attributes for Each Set\n",
        "rw.shape, ww.shape,  aw.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxOpZ6tlS-Qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Overview of what the data looks like\n",
        "aw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFWHO5D-tU3w",
        "colab_type": "text"
      },
      "source": [
        "### **Data Summary**\n",
        "Summary statistics show the datasets contain no missing values. The quality columns in both red and white datasets show mostly similiar values. However, many of the values for the predictor variables are further apart when comparing the two datasets. This means white wine will have almost three times the influence over the values in our combined dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4jhJggmr9Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Summarize Red Wine Data\n",
        "rw.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCQsuJzxmvNM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Histograms of Red Wine Attributes Side by Side\n",
        "#Create single figure for all histograms and the array that holds all histograms\n",
        "#Achieved through research and a combination of multiple ideas found from researching on google and stackexchange\n",
        "#Matplotlib package used\n",
        "fig, axarr = plt.subplots(3,4,figsize=(20,7))\n",
        "fig.suptitle('Histograms of Red Wine Attributes', fontsize=16)\n",
        "fig.tight_layout\n",
        "fig.subplots_adjust(top=0.95, hspace=0.3, wspace=0.4)\n",
        "\n",
        "#Create histograms in the array for each Red Wine attribute\n",
        "rw.quality.hist(ax=axarr[0,0])\n",
        "axarr[0,0].set_xlabel(\"Quality\")\n",
        "axarr[0,0].set_ylabel(\"Counts\")\n",
        "rw.alcohol.hist(ax=axarr[0,1])\n",
        "axarr[0,1].set_xlabel(\"Alcohol\")\n",
        "rw.density.hist(ax=axarr[0,2])\n",
        "axarr[0,2].set_xlabel(\"Density\")\n",
        "rw.residualSugar.hist(ax=axarr[0,3])\n",
        "axarr[0,3].set_xlabel(\"Residual Sugar\")\n",
        "rw.pH.hist(ax=axarr[1,0])\n",
        "axarr[1,0].set_xlabel(\"ph\")\n",
        "axarr[1,0].set_ylabel(\"Counts\")\n",
        "rw.sulphates.hist(ax=axarr[1,1])\n",
        "axarr[1,1].set_xlabel(\"Sulphates\")\n",
        "rw.freeSulfurDioxide.hist(ax=axarr[1,2])\n",
        "axarr[1,2].set_xlabel(\"Free Sulfur Dioxide\")\n",
        "rw.totalSulfurDioxide.hist(ax=axarr[1,3])\n",
        "axarr[1,3].set_xlabel(\"Total Sulfur Dioxide\")\n",
        "rw.chlorides.hist(ax=axarr[2,0])\n",
        "axarr[2,0].set_xlabel(\"Chlorides\")\n",
        "axarr[2,0].set_ylabel(\"Counts\")\n",
        "rw.fixedAcidity.hist(ax=axarr[2,1])\n",
        "axarr[2,1].set_xlabel(\"Fixed Acidity\")\n",
        "rw.volatileAcidity.hist(ax=axarr[2,2])\n",
        "axarr[2,2].set_xlabel(\"Volatile Acidity\")\n",
        "rw.citricAcid.hist(ax=axarr[2,3])\n",
        "axarr[2,3].set_xlabel(\"Citric Acid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLt69w1mrymf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Summarize White Wine Data\n",
        "ww.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSw6iLLEmdtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Histograms of White Wine Attributes Side by Side\n",
        "#Create figure and the array that holds all histograms\n",
        "fig, axarr = plt.subplots(3,4,figsize=(20,7))\n",
        "fig.suptitle('Histograms of White Wine Attributes', fontsize=16)\n",
        "fig.tight_layout\n",
        "fig.subplots_adjust(top=0.95, hspace=0.3, wspace=0.4)\n",
        "\n",
        "#Create histograms in the array for each Wed Wine attribute\n",
        "ww.quality.hist(ax=axarr[0,0])\n",
        "axarr[0,0].set_xlabel(\"Quality\")\n",
        "axarr[0,0].set_ylabel(\"Counts\")\n",
        "ww.alcohol.hist(ax=axarr[0,1])\n",
        "axarr[0,1].set_xlabel(\"Alcohol\")\n",
        "ww.density.hist(ax=axarr[0,2])\n",
        "axarr[0,2].set_xlabel(\"Density\")\n",
        "ww.residualSugar.hist(ax=axarr[0,3])\n",
        "axarr[0,3].set_xlabel(\"Residual Sugar\")\n",
        "ww.pH.hist(ax=axarr[1,0])\n",
        "axarr[1,0].set_xlabel(\"ph\")\n",
        "axarr[1,0].set_ylabel(\"Counts\")\n",
        "ww.sulphates.hist(ax=axarr[1,1])\n",
        "axarr[1,1].set_xlabel(\"Sulphates\")\n",
        "ww.freeSulfurDioxide.hist(ax=axarr[1,2])\n",
        "axarr[1,2].set_xlabel(\"Free Sulfur Dioxide\")\n",
        "ww.totalSulfurDioxide.hist(ax=axarr[1,3])\n",
        "axarr[1,3].set_xlabel(\"Total Sulfur Dioxide\")\n",
        "ww.chlorides.hist(ax=axarr[2,0])\n",
        "axarr[2,0].set_xlabel(\"Chlorides\")\n",
        "axarr[2,0].set_ylabel(\"Counts\")\n",
        "ww.fixedAcidity.hist(ax=axarr[2,1])\n",
        "axarr[2,1].set_xlabel(\"Fixed Acidity\")\n",
        "ww.volatileAcidity.hist(ax=axarr[2,2])\n",
        "axarr[2,2].set_xlabel(\"Volatile Acidity\")\n",
        "ww.citricAcid.hist(ax=axarr[2,3])\n",
        "axarr[2,3].set_xlabel(\"Citric Acid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZKmoDQq0sAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Summarize All Wine Data\n",
        "aw.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiqK2vXYa5WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Side-by-side Histograms Red and White Wine Attributes\n",
        "#Create figure and the array that holds all histograms\n",
        "fig, axarr = plt.subplots(3,4,figsize=(20,7))\n",
        "fig.suptitle('Histogram of Red and White Wine Attributes', fontsize=16)\n",
        "fig.tight_layout\n",
        "fig.subplots_adjust(top=0.95, hspace=0.3, wspace=0.4)\n",
        "\n",
        "#Create histograms in the array for each attribute in All Wine\n",
        "aw.quality.hist(ax=axarr[0,0])\n",
        "axarr[0,0].set_xlabel(\"Quality\")\n",
        "axarr[0,0].set_ylabel(\"Counts\")\n",
        "aw.alcohol.hist(ax=axarr[0,1])\n",
        "axarr[0,1].set_xlabel(\"Alcohol\")\n",
        "aw.density.hist(ax=axarr[0,2])\n",
        "axarr[0,2].set_xlabel(\"Density\")\n",
        "aw.residualSugar.hist(ax=axarr[0,3])\n",
        "axarr[0,3].set_xlabel(\"Residual Sugar\")\n",
        "aw.pH.hist(ax=axarr[1,0])\n",
        "axarr[1,0].set_xlabel(\"ph\")\n",
        "axarr[1,0].set_ylabel(\"Counts\")\n",
        "aw.sulphates.hist(ax=axarr[1,1])\n",
        "axarr[1,1].set_xlabel(\"Sulphates\")\n",
        "aw.freeSulfurDioxide.hist(ax=axarr[1,2])\n",
        "axarr[1,2].set_xlabel(\"Free Sulfur Dioxide\")\n",
        "aw.totalSulfurDioxide.hist(ax=axarr[1,3])\n",
        "axarr[1,3].set_xlabel(\"Total Sulfur Dioxide\")\n",
        "aw.chlorides.hist(ax=axarr[2,0])\n",
        "axarr[2,0].set_xlabel(\"Chlorides\")\n",
        "axarr[2,0].set_ylabel(\"Counts\")\n",
        "aw.fixedAcidity.hist(ax=axarr[2,1])\n",
        "axarr[2,1].set_xlabel(\"Fixed Acidity\")\n",
        "aw.volatileAcidity.hist(ax=axarr[2,2])\n",
        "axarr[2,2].set_xlabel(\"Volatile Acidity\")\n",
        "aw.citricAcid.hist(ax=axarr[2,3])\n",
        "axarr[2,3].set_xlabel(\"Citric Acid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRY7ddYr-ob2",
        "colab_type": "text"
      },
      "source": [
        "### **Detect Outliers** \n",
        "After reviewing the histograms for all three datasets, we can see that a lot of the attributes are skewed right. This suggests there may be outliers and, after examining the boxplots below for the attributes of the combined dataset of Red and White Wines, there appears to be many outliers outside of the Inter Quartile Range (middle 50% of data values). We can not assume any of these outliers are errors at this time due to the amount of them.\n",
        "\n",
        "However, at least two of these instances can be said to be rather significant, and future data models may want to be explored with out these entries; or at least an explanation of why the wine creation procces, whether natural or unnnatural, resulted those very high numbers. \n",
        "\n",
        "The values for quality, the target variable, are also all centered around the middle of the rankings on a scale of 1 to 10. The exact criteria for achieving these values for criteria should be examined. It is also important to note that not all data is scaled the same way and there are notable differences in the means between all datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_SrAKB3-ms5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Side-by-side Boxplots of Red and White Wine Attributes\n",
        "#Create figure and the array that holds all histograms\n",
        "fig, axarr = plt.subplots(3,4,figsize=(30,7))\n",
        "fig.suptitle('Boxplots of Red and White Wine Red and White Wine Attributes', fontsize=16)\n",
        "fig.tight_layout\n",
        "fig.subplots_adjust(top=0.95, hspace=0.3, wspace=0.4)\n",
        "\n",
        "#Create boxplots in the array for each attribute in All Wine\n",
        "#Seaborn Package used for boxplots\n",
        "sns.boxplot(aw.quality, ax=axarr[0,0])\n",
        "axarr[0,0].set_xlabel(\"Quality\")\n",
        "axarr[0,0].set_ylabel(\"Counts\")\n",
        "sns.boxplot(aw.alcohol,ax=axarr[0,1])\n",
        "axarr[0,1].set_xlabel(\"Alcohol\")\n",
        "sns.boxplot(aw.density,ax=axarr[0,2])\n",
        "axarr[0,2].set_xlabel(\"Density\")\n",
        "sns.boxplot(aw.residualSugar,ax=axarr[0,3])\n",
        "axarr[0,3].set_xlabel(\"Residual Sugar\")\n",
        "sns.boxplot(aw.pH,ax=axarr[1,0])\n",
        "axarr[1,0].set_xlabel(\"ph\")\n",
        "axarr[1,0].set_ylabel(\"Counts\")\n",
        "sns.boxplot(aw.sulphates,ax=axarr[1,1])\n",
        "axarr[1,1].set_xlabel(\"Sulphates\")\n",
        "sns.boxplot(aw.freeSulfurDioxide,ax=axarr[1,2])\n",
        "axarr[1,2].set_xlabel(\"Free Sulfur Dioxide\")\n",
        "sns.boxplot(aw.totalSulfurDioxide,ax=axarr[1,3])\n",
        "axarr[1,3].set_xlabel(\"Total Sulfur Dioxide\")\n",
        "sns.boxplot(aw.chlorides,ax=axarr[2,0])\n",
        "axarr[2,0].set_xlabel(\"Chlorides\")\n",
        "axarr[2,0].set_ylabel(\"Counts\")\n",
        "sns.boxplot(aw.fixedAcidity,ax=axarr[2,1])\n",
        "axarr[2,1].set_xlabel(\"Fixed Acidity\")\n",
        "sns.boxplot(aw.volatileAcidity,ax=axarr[2,2])\n",
        "axarr[2,2].set_xlabel(\"Volatile Acidity\")\n",
        "sns.boxplot(aw.citricAcid,ax=axarr[2,3])\n",
        "axarr[2,3].set_xlabel(\"Citric Acid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRM0bG6rZvvC",
        "colab_type": "text"
      },
      "source": [
        "## **Correlation**\n",
        "\n",
        "The overall correlation between most of our variables seems to be low. Our target variable seems to be most correlated with alcohol around .44. The strongest correlation we have is negative between density and alcohol; meaning as the amount of one increases, the other decreases. It should also be noted the correlations are a lot lower on average in the white wine dataset than the red wine dataset. Whether this is a result of the type of wine or the number of instances cannot be inferred."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT71o25J4bdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Correlation Visualization for Red Wine Features\n",
        "#Code retrieved from kaggle source listed at the bottom of this page\n",
        "#Calculate Correlation of attributes for Red Wine\n",
        "corrRW = rw.corr()\n",
        "\n",
        "#Create heatmap to display correlation values\n",
        "#Matplotlib.pyplot and Seaborn Packages used\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corrRW, vmax=1, square=True,annot=True,cmap='cubehelix')\n",
        "plt.title('Correlation between different Red Wine features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iSFvSe14bX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Correlation Visualization for White Wine Features\n",
        "#Calculate Correlation of attributes for White Wine\n",
        "corrWW = ww.corr()\n",
        "\n",
        "#Create heatmap to display correlation values\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corrWW, vmax=1, square=True,annot=True,cmap='cubehelix')\n",
        "plt.title('Correlation between different White Wine feaures')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNmU4bwwEtdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Correlation Visualization for Red and White Wine Features\n",
        "#Calculate Correlation of attributes for Combined Wine Data\n",
        "corrAW = aw.corr()\n",
        "\n",
        "#Create heatmap to display correlation values\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corrAW, vmax=1, square=True,annot=True,cmap='cubehelix')\n",
        "plt.title('Correlation between different features of Red and White Wine Combined')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LYJvnbV8LVx",
        "colab_type": "text"
      },
      "source": [
        "## **Seperate Out Features from the Target Variable Quality**\n",
        "\n",
        "We want to explore the principal components relating to only the features and don't want the numbers for quality affecting the overall explained variance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ_eMi371goG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Seperate Features from Target Variable\n",
        "#Identify Features\n",
        "features = ['fixedAcidity', 'volatileAcidity', 'citricAcid', 'residualSugar', 'chlorides','freeSulfurDioxide', 'totalSulfurDioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
        "\n",
        "#Seperate attributes from quality for Red Wine\n",
        "rwf = rw.loc[:, features].values\n",
        "rwq = rw.loc[:,['quality']].values\n",
        "\n",
        "#Seperate attributes from quality for White Wine\n",
        "wwf = ww.loc[:, features].values\n",
        "wwq = ww.loc[:,['quality']].values\n",
        "\n",
        "#Seperate attributes from quality for All Wine\n",
        "awf = aw.loc[:, features].values\n",
        "awq = aw.loc[:,['quality']].values\n",
        "\n",
        "#Ensure the data was preserved\n",
        "rwf.shape, wwf.shape, awf.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4V_Sb52NZou",
        "colab_type": "text"
      },
      "source": [
        "## **Principle Component Analysis: No Standardization**\n",
        "Without standardizing our data, after running the code below, we can see that the first principal component is accounting for around 90% of the explained variance.  This suggests the weights are not spread evenly between our features and the larger valued attributes are influencing the the first principle component the most"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDE5OqIpYn0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Perform PCA analysis with all untransformed datasets and barcharts for the resulting principal components \n",
        "#Create the figure and the array that holds all barplots\n",
        "fig, axarr = plt.subplots(1,3,figsize=(20,5))\n",
        "fig.suptitle('Percentage of Explained Variance Per Principle Component', fontsize=16)\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.9, wspace=0.1)\n",
        "\n",
        "#PCA transformation for Red Wine Features\n",
        "#sklearn.decomposition Package for PCA used\n",
        "#Process learned from sources listed at the end of this file\n",
        "pcaRW = PCA()\n",
        "pcaRW.fit(rwf)\n",
        "pca_RW = pcaRW.transform(rwf)\n",
        "\n",
        "#PCA transformation for White Wine Features\n",
        "pcaWW = PCA()\n",
        "pcaWW.fit(wwf)\n",
        "pca_WW = pcaWW.transform(wwf)\n",
        "\n",
        "#PCA transformation for All Wine Features\n",
        "pcaAW = PCA()\n",
        "pcaAW.fit(awf)\n",
        "pca_AW = pcaAW.transform(awf)\n",
        "\n",
        "#Calculate and round the explained variance for the PCA transformation of Red Wine features\n",
        "#Proccess learned from StatQuest Youtube video listed in sources below\n",
        "#sklearn.decomposition package used for calculating explained variance\n",
        "#numpy package used for rounding\n",
        "perVarRW = np.round(pcaRW.explained_variance_ratio_*100, decimals = 4)\n",
        "\n",
        "#Calculate and round the explained variance for the PCA transformation of White Wine features\n",
        "perVarWW = np.round(pcaWW.explained_variance_ratio_*100, decimals = 4)\n",
        "\n",
        "#Calculate and round the explained variance for the PCA transformation of All Wine features\n",
        "perVarAW = np.round(pcaAW.explained_variance_ratio_*100, decimals = 4)\n",
        "\n",
        "#Calculate and round the explained variance for the PCA transformation of White Wine features\n",
        "#Create principal componenet labels for barplots\n",
        "#Proccess learned from StatQuest Youtube video listed in sources below\n",
        "label1 = ['PC' + str(x) for x in range(1, len(perVarRW)+1)]\n",
        "label2 = ['PC' + str(x) for x in range(1, len(perVarWW)+1)]\n",
        "label3 = ['PC' + str(x) for x in range(1, len(perVarAW)+1)]\n",
        "\n",
        "#Insert data from each PCA transformation into array and barplots\n",
        "#Proccess learned from StatQuest Youtube video listed in sources below\n",
        "axarr[0].bar(x=range(1,len(perVarRW)+1), height = perVarRW, tick_label=label1)\n",
        "axarr[1].bar(x=range(1,len(perVarWW)+1), height = perVarWW, tick_label=label1)\n",
        "axarr[2].bar(x=range(1,len(perVarAW)+1), height = perVarAW, tick_label=label1)\n",
        "\n",
        "#Label barplots\n",
        "axarr[0].set_xlabel(\"Number of Components Red Wine\")\n",
        "axarr[0].set_ylabel(\"Percentage of Explained Variance\")\n",
        "axarr[1].set_xlabel(\"Number of Components White Wine\")\n",
        "axarr[2].set_xlabel(\"Number of Components All Wine\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS46OP65QG07",
        "colab_type": "text"
      },
      "source": [
        "# **Principal Component Analysis**\n",
        "As we saw above, one principal component accounted for most of the variance. PCA is performed to identify the principal components with the highest variance, so we need to standardize the data. Since the values for each of the features were not measured along the same scale, this will allow the attributes with the smaller values to make equal contributions to the principal components and spread the variance more evenly over all of the principal components.\n",
        "\n",
        "We will demonstrate the full proccess with the All Wine dataset, and then use the PCA Package in sklearn on the others to save time.\n",
        "\n",
        "Process followed for both calculation and sklearn package from Sebastian Raschka's website and the Kaggle sources listed at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efqNwuQTRe0c",
        "colab_type": "text"
      },
      "source": [
        "###**Step 1: Data Standardization**\n",
        "The features will be transformed to have a mean of 0 and a standard deviation of 1 so that all attributes  have the same unit scale, the data is centered, and ensure its normally distributed for optimal results. \n",
        "\n",
        "The mathematical process to achieve a more standard and normally distributed dataset is done be subtracting the means of each attribute from all of the corresponding attribute's values. If the data is viewed visually, it will show that the curve has shifted towards the orgin, but the shape of the curve is preserved.\n",
        "\n",
        "After obtaining a more normal distribution, each attributes standard deviation is divided by all of the attribute's corresponding data values. This will give the data a new standard deviation of 1. Recall that standard deviation is a measure of how spread out the data values are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5XDFhXE12f4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standardize datasets\n",
        "#sklearn.preprocessing package used for Standard Scaler\n",
        " \n",
        "#Transform Red Wine Features Dataset\n",
        "stdRW = StandardScaler().fit_transform(rwf)\n",
        "#Transform Red Wine Features Dataset\n",
        "stdWW = StandardScaler().fit_transform(wwf)\n",
        "#Transform Red Wine Features Dataset\n",
        "stdAW = StandardScaler().fit_transform(awf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNfd6fulZTxF",
        "colab_type": "text"
      },
      "source": [
        "### **Step 2: Covariance Matrix**\n",
        "\n",
        "In order to perform PCA, we need to obtain the covariance matrix for our data. This will allow us to perform eigendecomposition to find the eigenvalues and eigenvectors. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uBnvdB2VbcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculate mean vector\n",
        "#Numpy Package used\n",
        "meansAW = np.mean(stdAW, axis=0)\n",
        "\n",
        "#Display Mean Vector\n",
        "meansAW"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtxn0AEZWHIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculate Covariance Matrix\n",
        "covMatAWC = (stdAW - meansAW).T.dot((stdAW-meansAW))/(stdAW.shape[0]-1)\n",
        "\n",
        "#Display Covariance Matrix\n",
        "covMatAWC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0rm3SzrXz1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Correlation Visualization for Red Wine Features\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.heatmap(covMatAWC, vmax=1, square=True,annot=True,cmap='cubehelix')\n",
        "plt.title('Correlation between different features for All Wine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGQ2fAfuXUjw",
        "colab_type": "text"
      },
      "source": [
        "### **Step 3: Eigendecomposition**\n",
        "We will now retrieve the eigenvector and eigenvalues from the covariance matrix.\n",
        "\n",
        "The eigenvectors are the principal components and are representative of the direction with the greatest variance in the dataset. Specifically, each eigenvector, if placed on a plot of the original data, would be a line representative of a relationship between all the data in the set and perpendicular to all other eigenvectors.\n",
        "\n",
        "The eigenvalues correspond to the amount of variance there is along a specific eigenvector. Larger values explain more variance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBtUFxtLXRMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculate Eigenvalues and EigenVectors\n",
        "#Numpy Package used for the linear algebra calculations of the eigenvectors and eigenvaules\n",
        "eigvalsAWC , eigvecsAWC = np.linalg.eig(covMatAWC)\n",
        "\n",
        "#Show results\n",
        "print('\\nEigenvectors All Wine Calculated\\n%s' %eigvecsAWC)\n",
        "print('\\nEigenvalues All Wine Calculated\\n%s' %eigvalsAWC)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVt442JBd12P",
        "colab_type": "text"
      },
      "source": [
        "### **Step 4: Select Principal Components**\n",
        "Sort eigenvalues from largest to smallest in order to find the smallest ones. The smaller the eigenvalue, the less importance they have in representing the data distribution. The largest eigenvalue and its corresponding eigenvector is the principal component with the strongest relationship between the data and the new dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swpKE38bd2Jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pair eigenvalues and eigenvectors in list\n",
        "eigPairsAWC = [(np.abs(eigvalsAWC[i]), eigvecsAWC[:,i]) for i in range (len(eigvalsAWC))]\n",
        "\n",
        "#Sorts above list ffrom largest to smallest and print the eigenvalues\n",
        "eigPairsAWC.sort(key=lambda x: x[0], reverse=True)\n",
        "print('Eigenvalues for All Wine Calculated')\n",
        "for i in eigPairsAWC:\n",
        "  print(i[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrNU85i4d2UP",
        "colab_type": "text"
      },
      "source": [
        "### **Step 5: Calculate Explained Variance**\n",
        "\n",
        "The first two principal components clearly contribute to much more of the total variance than the rest of the components. We can also see some eigenvalues have very low values. Eigenvalues near zero are generally discarded for principal component analysis.\n",
        "\n",
        "However, we need to calculate the explained variance ratio for each principal component in order to tell us exaclty how much information each principal compontent accounts for. Doing so will allow us to properly select the principal components that can be removed from the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uwaRleSd2bf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculate Explained Variance\n",
        "#Add all eigenvalues together for total variance\n",
        "totVar = sum(eigvalsAWC)\n",
        "\n",
        "#Calculate the percantage of the contribution to variance for each principal component\n",
        "expVar = [(i/totVar)*100 for i in sorted(eigvalsAWC, reverse=True)]\n",
        "\n",
        "#Plot Explained variance of each Principal Component\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.bar(range(11), expVar)\n",
        "plt.ylabel('Explained Variance')\n",
        "plt.xlabel('Principal Components')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYlCTCNo7v5W",
        "colab_type": "text"
      },
      "source": [
        "After performing the calculations, the barplot shows the variance is much more spread out along the principal components and the first one is no longer accounting for 90% of the variance, but only around 27%. PC10 contributes very little and the 11th component isn't even listed, suggesting it explains none of the variance.\n",
        "\n",
        "Once the significant principal components are chosen, their eigenvectors are transposed and multiplied on the left side of the origial data to give a dataset with smaller dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4GQKOmNkRWB",
        "colab_type": "text"
      },
      "source": [
        "## **Principal Component Analysis with sklearn Package**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6mTKuk3EnCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Perform PCA with all components on standardized datasets\n",
        "\n",
        "#PCA transformation for Red Wine Features\n",
        "pca1 = PCA()\n",
        "pcaStdRW = pca1.fit_transform(stdRW)\n",
        "\n",
        "#PCA transformation for White Wine Features\n",
        "pca2 = PCA()\n",
        "pcaStdWW = pca2.fit_transform(stdWW)\n",
        "\n",
        "#PCA transformation for All Wine Features\n",
        "pca3 = PCA()\n",
        "pcaStdAW = pca3.fit_transform(stdAW)                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgZHNxaHiFZy",
        "colab_type": "text"
      },
      "source": [
        "### **Visualize Principal Components and their Explained Variance**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWFqnrF87B6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualizae Explained Variance\n",
        "#Create the figure and the array that holds all barplots\n",
        "fig, axarr = plt.subplots(1,3,figsize=(20,5))\n",
        "fig.suptitle('Percentage of Explained Variance Per Principle Component', fontsize=16)\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.9, wspace=0.1)\n",
        "\n",
        "\n",
        "#Calculate and round the explained variance for the PCA transformation of Red Wine features\n",
        "perVarStdRW = np.round(pca1.explained_variance_ratio_*100, decimals = 4)\n",
        "\n",
        "#Calculate and round the explained variance for the PCA transformation of White Wine features\n",
        "perVarStdWW = np.round(pca2.explained_variance_ratio_*100, decimals = 4)\n",
        "\n",
        "#Calculate and round the explained variance for the PCA transformation of All Wine features\n",
        "perVarStdAW = np.round(pca3.explained_variance_ratio_*100, decimals = 4)\n",
        "\n",
        "#Create principal componenet labels for barplots\n",
        "label1 = ['PC' + str(x) for x in range(1, len(perVarStdRW)+1)]\n",
        "label2 = ['PC' + str(x) for x in range(1, len(perVarStdWW)+1)]\n",
        "label3 = ['PC' + str(x) for x in range(1, len(perVarStdAW)+1)]\n",
        "\n",
        "#Insert data from each PCA transformation into array and barplots\n",
        "axarr[0].bar(x=range(1,len(perVarStdRW)+1), height = perVarStdRW, tick_label=label1)\n",
        "axarr[1].bar(x=range(1,len(perVarStdWW)+1), height = perVarStdWW, tick_label=label1)\n",
        "axarr[2].bar(x=range(1,len(perVarStdAW)+1), height = perVarStdAW, tick_label=label1)\n",
        "\n",
        "#Label barplots\n",
        "axarr[0].set_xlabel(\"Number of Components Red Wine\")\n",
        "axarr[0].set_ylabel(\"Percentage of Explained Variance\")\n",
        "axarr[1].set_xlabel(\"Number of Components White Wine\")\n",
        "axarr[2].set_xlabel(\"Number of Components All Wine\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEsR87nd209j",
        "colab_type": "text"
      },
      "source": [
        "We can see the resulting principal components for each of the three datasets and the ammounts of variance contributed by each one. It is interesting to see that the second principal component in the all wine dataset contributes significantly more to the total variance than the second component in the other datasets. This may be something to explore further in the future. It can also be seen that the variance in the Red Wine distribution seems to decrease at a more even ratio as viewing the plot from PC1 to PC11. It is interesting to note that PC11 for All Wine is shown with the pca method from sklearn package, but wasn't shown with the longer method above; however, quite clearly it contributes very little in all datasets and is a candidate for removal. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF3hSbRb4K7y",
        "colab_type": "text"
      },
      "source": [
        "### **Visualize the Total Explained Variance Accounted for as the Number of Principal Components Increases**\n",
        "To aid us further in selecting the principal components to remove, we will visualize the total variance accounted for as more principal components are included. This additional step was taken from the kaggle source.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBGaJfIj7CDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualize Explained Variance as Number of Principal Components Increases\n",
        "#Create the figure and the array that holds all barplots\n",
        "fig, axarr = plt.subplots(1,3,figsize=(20,5))\n",
        "fig.suptitle('Explained Variance vs Number of Components', fontsize=16)\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.9, wspace=0.1)\n",
        "\n",
        "#Matplotlib.pyplot used for plotting data\n",
        "#sklearn packge used for calculating the explained variance of each principal component\n",
        "#Numpy package used for calculating the total variance of all principal components\n",
        "#Calculate Total Explained Variance and Create plots for Red Wine Principal Components and their corresponding Explained Variance Values\n",
        "axarr[0].plot(np.cumsum(pca1.explained_variance_ratio_))\n",
        "axarr[0].set_xlabel(\"Number of Components Red Wine\")\n",
        "axarr[0].set_ylabel(\"Cumulative Explained Variance\")\n",
        "#Insert dashed line to show the cutoff point we used for explained variance at 90%\n",
        "axarr[0].axhline(y=0.9,color='gray',linestyle='--')\n",
        "\n",
        "#Calculate Total Explained Variance and Create plots for Red Wine Principal Components and their corresponding Explained Variance Values\n",
        "axarr[1].plot(np.cumsum(pca2.explained_variance_ratio_))\n",
        "axarr[1].set_xlabel(\"Number of Components White Wine\")\n",
        "axarr[1].axhline(y=0.9,color='gray',linestyle='--')\n",
        "\n",
        "#Calculate Total Explained Variance and Create plots for Red Wine Principal Components and their corresponding Explained Variance Values\n",
        "axarr[2].plot(np.cumsum(pca3.explained_variance_ratio_))\n",
        "axarr[2].set_xlabel(\"Number of Components All Wine\")\n",
        "axarr[2].axhline(y=0.9,color='gray',linestyle='--')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6jJ8wGV2Vb_",
        "colab_type": "text"
      },
      "source": [
        "From the resulting plots, we can see that there is just about 90% Explained Variance in all standardized datasets at the sixth principal component, and therefore we can drop the remaining components because they provide little information. \n",
        "\n",
        "The 90% cutoff is generally the minimum total variance that should be accounted for and was chosen for no particular reason; however, many often look for the principal components that account for 95% of total variance or even 99% of total variance. Doing so would result in choosing 7 and 8 principal components, respectively.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhOsVRQX13Qb",
        "colab_type": "text"
      },
      "source": [
        "### **Perform Principal Component Analysis with Six Principal Components**\n",
        "Besides PCA, we will also merge the six principal components back with the target variable in order to visualize them together. For the All Wine Principal Components, we attempted, but were unable to create a function that would join them with the quality values. A special method is needed, since the All Wine dataset was originaly created by joining two datasets. If it is desired to use that data for machine learning methods, it might be more appropriate if the All Wine dataset created outside of python, loaded in, and then transformed with the procedure above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHsFLb8viDuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Perform PCA with desired components of 6\n",
        "\n",
        "#PCA on Standardized Red Wine Data with only 6 Principal Components\n",
        "pcaRW6 = PCA(n_components=6)\n",
        "pcaRW6.fit(stdRW)\n",
        "pca_StdRW = pcaRW6.transform(stdRW)\n",
        "\n",
        "#PCA on Standardized White Wine Data with only 6 Principal Components\n",
        "pcaWW6 = PCA(n_components=6)\n",
        "pcaWW6.fit(stdWW)\n",
        "pca_StdWW = pcaWW6.transform(stdWW)\n",
        "\n",
        "#PCA on Standardized All Wine Data with only 6 Principal Components\n",
        "pcaAW6 = PCA(n_components=6)\n",
        "pcaAW6.fit(stdAW)\n",
        "pca_StdAW = pcaAW6.transform(stdAW)\n",
        "\n",
        "\n",
        "#Create Dataframes of Principal Components for each wine Dataset\n",
        "finalPrincipalRW = pd.DataFrame(data= pca_StdRW , columns = ['Principal Component 1','Principal Component 2','Principal Component 3',\n",
        "                                                         'Principal Component 4','Principal Component 5','Principal Component 6'])\n",
        "finalPrincipalWW = pd.DataFrame(data= pca_StdWW, columns = ['Principal Component 1','Principal Component 2','Principal Component 3',\n",
        "                                                         'Principal Component 4','Principal Component 5','Principal Component 6'])\n",
        "finalPrincipalAW = pd.DataFrame(data= pca_StdAW, columns = ['Principal Component 1','Principal Component 2','Principal Component 3',\n",
        "                                                         'Principal Component 4','Principal Component 5','Principal Component 6'])\n",
        "\n",
        "\n",
        "#Merge Red Wine Principal Components with the Target Variable\n",
        "finalRW = pd.concat([finalPrincipalRW, rw[['quality']]], axis = 1)\n",
        "\n",
        "#Merge White Wine Principal Components with the Target Variable\n",
        "finalWW = pd.concat([finalPrincipalWW, ww[['quality']]], axis = 1)\n",
        "\n",
        "#Special Join Needed for All Wine Components due to the fact the orginal dataset was created by concating two datasets. \n",
        "#Unable to figure out how to do correctly\n",
        "#frames = [rw[['quality']], ww[['quality']]]\n",
        "#qualityAW = pd.concat(frames, keys=['Red Wine', 'White Wine'])\n",
        "#finalAW = pd.merge(left=finalPrincipalAW, right=qualityAW, left_on='Principal Component 6', right_on='quality')\n",
        "#finalAW = finalPrincipalAW.join(qualityAW.set_index('quality'), on='quality')\n",
        "\n",
        "#Display Red Wine Principal Componets with corresponding Quality Values\n",
        "finalRW"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jARcm4bq0dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Display White Wine Principal Componets with corresponding Quality Values\n",
        "finalWW"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PloVbWEvy1w",
        "colab_type": "text"
      },
      "source": [
        "# **Results**\n",
        "We were able to remove five principal components from our datasets. This will make sure models for prediction of wine quality or other machine learning methods are much easier in the future compared. Almost half of the data has been removed and the dimensions have been successully reduced to six, without losing much total variance. The correlations between our principal components can be seen to be much lower, in the visualizations below, than the correlations between the attributes in our original datasets. \n",
        "\n",
        "We now have six, instead of eleven, attributes that can be used for machine learning methods in the determination of quality or other explorations, a significantly lower number of dimensions to work with. Depending on the goal, it may be appropriate to use more principal components to account for more variance and it should be noted that the number of principal components used for White Wine should probably be one more than the other datasets as the plot above shows 90% total variance is accounted for closer to the 7th, not 6th principal component. The descision for percentage of total variance to aim for in principal components, in general, will largely depend on the number of attributes in the original dataset and the desired machine learing outcome.\n",
        "\n",
        "Future explorations should include investigation of outliers and varying transformations (log, square root, inverse suqare root) of the original data to possibly allow for elimination of additional principal components and further reduction in dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrcK56ivxKUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Correlation Visualization for Red Wine Features\n",
        "#Calculate Correlation of the Red Wine Principal Components\n",
        "corrfinalRW = finalRW.corr()\n",
        "\n",
        "#Create Figure from correlation data\n",
        "#Matplotlib.pyplot and Seaborn Packages used\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corrfinalRW, vmax=1, square=True,annot=True,cmap='cubehelix')\n",
        "plt.title('Correlation between different components of Red Wine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARWYojAmyEPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Correlation Visualization for White Wine Features\n",
        "#Calculate Correlation of the White Wine Principal Components\n",
        "corrfinalWW = finalWW.corr()\n",
        "\n",
        "#Create Figure\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(corrfinalWW, vmax=1, square=True,annot=True,cmap='cubehelix')\n",
        "plt.title('Correlation between different components of White Wine')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaqRtAzJOlNV",
        "colab_type": "text"
      },
      "source": [
        "# **Sources**\n",
        "\n",
        "The following Sources were used more for coding purposes. A lot of coding for visualizations, arrays, and some other smaller aspects were put together from numerous google search results and past experience. The experience for exploring datasets in more detail was learned from Towsons COSC 431 Selected Topics Course on Data Mining. \n",
        "\n",
        "https://www.kaggle.com/nirajvermafcb/principal-component-analysis-explained\n",
        "\n",
        "http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html\n",
        "\n",
        "https://www.youtube.com/watch?v=Lsue2gEM9D0&list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&index=27&t=0s\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "These sources were used for simpler explanations throughout the project's descriptions and analysis portions.\n",
        "\n",
        "http://www.lauradhamilton.com/introduction-to-principal-component-analysis-pca\n",
        "\n",
        "https://365datascience.com/standardization/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL0FlCigCJ21",
        "colab_type": "text"
      },
      "source": [
        "# **Dataset Source**\n",
        "https://archive.ics.uci.edu/ml/datasets/Wine+Quality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVcV_vL7ORTN",
        "colab_type": "text"
      },
      "source": [
        "# **Contributors**\n",
        "\n",
        "Nathan Koh - nkoh1@students.towson.edu\n",
        "\n",
        "Craig Neely - cneely6@students.towson.edu\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Group Project\n",
        "\n",
        "Math 490\n",
        "\n",
        "Towson University"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6ojfoPQR0v2",
        "colab_type": "text"
      },
      "source": [
        "# **Visualization Experiments**\n",
        "The following two blocks of code are our attempts at visualizing the correlation heatmaps, from the Seaborn package, for each dataset all together in one figure with gridspec from the matplotlib package. The numerous annotations on each figure and the colorbars are the main contributers to the difficulties experienced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1yWsxQD7CTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create figure and array to display all heatmaps together\n",
        "fig, axarr = plt.subplots(1,3,figsize=(40,40))\n",
        "fig.suptitle('Correlation Heatmap', fontsize=40)\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=.9999, wspace=0.2, hspace=0)\n",
        "\n",
        "#Modify Colorbar\n",
        "cbar_ax = fig.add_axes([1, .33, .05, .35])\n",
        "\n",
        "#Create Correlation Heatmaps for All Datasets\n",
        "sns.heatmap(corrRW, vmax=1, square=True, annot=True,cmap='cubehelix', cbar=False, ax=axarr[0])\n",
        "sns.heatmap(corrWW, vmax=1, square=True, annot=True,cmap='cubehelix', cbar=False, ax=axarr[1])\n",
        "sns.heatmap(corrAW, vmax=1, square=True, annot=True,cmap='cubehelix', cbar_ax= cbar_ax, ax=axarr[2])\n",
        "\n",
        "#Label specific subplots\n",
        "axarr[0].set_xlabel('Correlation between different Red Wine fearures', fontsize=16)\n",
        "axarr[1].set_xlabel('Correlation between different White Wine fearures', fontsize=16)\n",
        "axarr[2].set_xlabel('Correlation between different All Wine fearures', fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3L11UKlfZJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Another attempt to create figure using gridspec instead.\n",
        "fig, (ax1,ax2,ax3, axcb) = plt.subplots(1,4,figsize=(40, 40), gridspec_kw={'width_ratios':[1,1,1,.08]})\n",
        "ax1.get_shared_y_axes().join(ax2,ax3)\n",
        "#fig, axarr = plt.subplots(1,3,figsize=(40,40))\n",
        "fig.suptitle('Principle Component Analysis: No Normalization', fontsize=16)\n",
        "\n",
        "#fig.subplots_adjust(top=0.95, wspace=0.2, hspace=0)\n",
        "\n",
        "#Create Correlation Heatmaps\n",
        "g1 = sns.heatmap(corrRW, vmax=1, square=True, annot=True,cmap='cubehelix', cbar=False, ax=ax1)\n",
        "g1.set_ylabel('')\n",
        "g1.set_xlabel('')\n",
        "g2 = sns.heatmap(corrWW, vmax=1, square=True, annot=True,cmap='cubehelix', cbar=False, ax=ax2)\n",
        "g2.set_ylabel('')\n",
        "g2.set_xlabel('')\n",
        "g2.set_yticks([])\n",
        "g3 = sns.heatmap(corrAW, vmax=1, square=True,annot=True,cmap='cubehelix', cbar_kws={'shrink':[0.0001]}, cbar_ax=axcb, ax=ax3)\n",
        "g3.set_ylabel('')\n",
        "g3.set_xlabel('')\n",
        "g3.set_yticks([])\n",
        "\n",
        "#Label Specific Subplots\n",
        "axarr[0].set_xlabel('Correlation between different Red Wine fearures', fontsize=16)\n",
        "axarr[1].set_xlabel('Correlation between different White Wine fearures', fontsize=16)\n",
        "axarr[2].set_xlabel('Correlation between different All Wine fearures', fontsize=16)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hawv7vvaFD3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}